# -*- coding: utf-8 -*-
"""Validation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RXQ7XuEOoQEKNth-kVWWHjrZtFPOnC9Q
"""

!pip install torch torchvision pillow numpy matplotlib

from google.colab import files
import os
import zipfile

!rm -rf /content/dataset

print("Upload dataset (6).zip or equivalent dataset zip file")
uploaded = files.upload()

zip_file = next((f for f in uploaded.keys() if f.endswith('.zip')), None)
if zip_file:
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        zip_ref.extractall(".")
    print("Top-level directories:", os.listdir("."))
    if os.path.exists("dataset"):
        print("Dataset structure after unzip:", os.listdir("dataset"))
        nested_dir = os.path.join("dataset", "dataset")
        if os.path.exists(nested_dir):
            print(f"Nested dataset folder found at {nested_dir}. Using this as root_dir.")
            dataset_root = nested_dir
            print("Nested dataset contents:", os.listdir(nested_dir))
        else:
            dataset_root = "dataset"
        validation_dir = os.path.join(dataset_root, "validation")
        if os.path.exists(validation_dir):
            print("Validation directory contents:", os.listdir(validation_dir))
            if os.path.exists(os.path.join(validation_dir, "data.json")):
                print("Found validation/data.json")
            else:
                print("Error: validation/data.json not found")
        else:
            print(f"Error: {validation_dir} not found")
    else:
        raise RuntimeError("Failed to unzip dataset. Directory ./dataset not created.")
else:
    raise FileNotFoundError("No .zip file uploaded")

import wandb

print("Option 1: Upload best_unet_model.pth from training notebook (or skip to use wandb)")
uploaded = files.upload()

model_files = [f for f in uploaded.keys() if f.startswith('best_unet_model')]
if model_files:
    os.rename(model_files[0], 'best_unet_model.pth')
    print(f"Renamed {model_files[0]} to best_unet_model.pth")
else:
    model_uploaded = os.path.exists("best_unet_model.pth")

if not os.path.exists("best_unet_model.pth"):
    print("Option 2: Fetching best_unet_model.pth from wandb")
    wandb.login()
    run = wandb.init(project="ayna_ml_assignment", id="y2fphtu4")
    artifact = run.use_artifact('model:latest')
    artifact.download()
    if os.path.exists('./artifacts/best_unet_model.pth'):
        os.rename('./artifacts/best_unet_model.pth', 'best_unet_model.pth')
    else:
        raise FileNotFoundError("best_unet_model.pth not found in wandb artifacts. Ensure it was saved in training.")

if not os.path.exists("best_unet_model.pth"):
    raise FileNotFoundError("best_unet_model.pth not found. Please upload or fetch from wandb.")

import torch
import torch.nn as nn

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=3, num_colors=8):
        super(UNet, self).__init__()
        self.num_colors = num_colors

        def conv_block(in_ch, out_ch):
            block = nn.Sequential(
                nn.Conv2d(in_ch, out_ch, 3, padding=1),
                nn.BatchNorm2d(out_ch),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_ch, out_ch, 3, padding=1),
                nn.BatchNorm2d(out_ch),
                nn.ReLU(inplace=True)
            )
            for m in block.modules():
                if isinstance(m, nn.Conv2d):
                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
            return block

        self.enc1 = conv_block(in_channels + num_colors, 64)
        self.enc2 = conv_block(64, 128)
        self.enc3 = conv_block(128, 256)
        self.enc4 = conv_block(256, 512)
        self.pool = nn.MaxPool2d(2, 2)

        self.bottleneck = conv_block(512, 1024)

        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)
        self.dec4 = conv_block(1024, 512)
        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.dec3 = conv_block(512, 256)
        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = conv_block(256, 128)
        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = conv_block(128, 64)
        self.final = nn.Conv2d(64, out_channels, 1)

    def forward(self, x, color_vector):
        color_vector = color_vector[:, :, None, None].expand(-1, -1, x.size(2), x.size(3))
        x = torch.cat([x, color_vector], dim=1)
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))
        b = self.bottleneck(self.pool(e4))
        d4 = self.up4(b)
        d4 = torch.cat([d4, e4], dim=1)
        d4 = self.dec4(d4)
        d3 = self.up3(d4)
        d3 = torch.cat([d3, e3], dim=1)
        d3 = self.dec3(d3)
        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)
        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)
        out = self.final(d1)
        return torch.sigmoid(out)

import json
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import os

dataset_root = 'dataset/dataset'

training_color_map = {
    'cyan': 0, 'purple': 1, 'magenta': 2, 'green': 3,
    'red': 4, 'blue': 5, 'yellow': 6, 'orange': 7
}

with open(f'{dataset_root}/validation/data.json', 'r') as f:
    data = json.load(f)

if data:
    print("Sample validation data.json entry:", data[0])

color_key = None
possible_keys = ['color', 'colour', 'label', 'class']
for key in possible_keys:
    if key in data[0]:
        color_key = key
        break
if color_key is None:
    raise KeyError(f"No valid color key found in validation data.json. Tried: {possible_keys}. Sample entry: {data[0]}")

val_color_map = {}
for i, entry in enumerate(data):
    color = entry[color_key]
    if color not in val_color_map:
        val_color_map[color] = training_color_map.get(color, len(training_color_map))
print("Validation color map mapped to training indices:", val_color_map)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(num_colors=8).to(device)
model.load_state_dict(torch.load('best_unet_model.pth', map_location=device))
model.eval()

transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

def infer_polygon(image_path, color_name):
    input_img = Image.open(image_path).convert('L')
    if transform:
        seed = np.random.randint(2147483647)
        torch.manual_seed(seed)
        input_img = transform(input_img)
    input_img = input_img.unsqueeze(0).to(device)

    if color_name not in val_color_map:
        raise ValueError(f"Color {color_name} not in validation color map: {val_color_map.keys()}")
    color_idx = val_color_map[color_name]
    color_vector = torch.zeros(1, 8).to(device)
    color_vector[0, color_idx] = 1.0

    with torch.no_grad():
        pred = model(input_img, color_vector).cpu().squeeze().numpy().transpose(1, 2, 0)

    return input_img.cpu().squeeze().numpy(), pred, seed

print("Available shapes in validation/inputs:", os.listdir(os.path.join(dataset_root, 'validation', 'inputs')))
selected_shape = input("Enter shape file name (e.g., star.png) from the list above: ")
input_path = os.path.join(dataset_root, 'validation', 'inputs', selected_shape)

print("Available colors:", list(val_color_map.keys()))
selected_color = input("Enter color (e.g., yellow) from the list above: ")

if not os.path.exists(input_path):
    raise FileNotFoundError(f"Shape {selected_shape} not found in {input_path}")
if selected_color not in val_color_map:
    raise ValueError(f"Color {selected_color} not valid. Use: {list(val_color_map.keys())}")

gt_file = None
for entry in data:
    if entry['input_polygon'] == selected_shape and entry['colour'] == selected_color:
        gt_file = entry['output_image']
        break

input_img, pred_img, seed = infer_polygon(input_path, selected_color)

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title("Input")
plt.imshow(input_img, cmap='gray')
plt.axis('off')
plt.subplot(1, 3, 2)
plt.title(f"Predicted ({selected_color})")
plt.imshow(pred_img)
plt.axis('off')

if gt_file and os.path.exists(os.path.join(dataset_root, 'validation', 'outputs', gt_file)):
    plt.subplot(1, 3, 3)
    plt.title("Ground Truth")
    gt_img = Image.open(os.path.join(dataset_root, 'validation', 'outputs', gt_file)).convert('RGB')
    torch.manual_seed(seed)
    gt_img = transform(gt_img).numpy().transpose(1, 2, 0)
    plt.imshow(gt_img)
    plt.axis('off')
else:
    plt.subplot(1, 3, 3)
    plt.title("No Ground Truth Available")
    plt.axis('off')
    print(f"No ground truth found for {selected_color}_{selected_shape}. Showing prediction only.")

plt.show()